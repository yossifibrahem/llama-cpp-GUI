{
    "model_path": "C:/Users/yossi/.cache/lm-studio/models/lmstudio-community/gpt-oss-20b-GGUF/gpt-oss-20b-MXFP4.gguf",
    "alias": "GPT-OSS-20b",
    "host": "127.0.0.1",
    "port": "8080",
    "api_key": "",
    "ctx_size": 32768,
    "gpu_layers": 99,
    "threads": "",
    "batch_size": "",
    "parallel": "",
    "cont_batching": true,
    "flash_attn": true,
    "mlock": false,
    "no_mmap": true,
    "numa": false,
    "moe_cpu_layers": "4",
    "chat_template": "",
    "lora_path": "",
    "mmproj_path": "",
    "draft_model_path": "",
    "draft_gpu_layers": "",
    "draft_tokens": "",
    "embedding": false,
    "jinja": true,
    "no_webui": false,
    "verbose": false,
    "custom_args": ""
}