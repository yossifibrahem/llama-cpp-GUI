{
    "model_path": "C:/Users/yossi/.cache/lm-studio/models/lmstudio-community/gpt-oss-20b-GGUF/gpt-oss-20b-MXFP4.gguf",
    "alias": "gpt-oss-20b",
    "lora_path": "",
    "mmproj_path": "",
    "chat_template": "",
    "reasoning_effort": "",
    "jinja": true,
    "ctx_size": 32768,
    "gpu_layers": 99,
    "threads": "",
    "batch_size": "",
    "cont_batching": true,
    "parallel": "",
    "flash_attn": true,
    "mlock": false,
    "no_mmap": true,
    "numa": false,
    "moe_cpu_layers": "4",
    "draft_model_path": "",
    "draft_gpu_layers": "",
    "draft_tokens": "",
    "host": "127.0.0.1",
    "port": "4321",
    "api_key": "",
    "no_webui": false,
    "embedding": false,
    "verbose": false,
    "custom_arguments_list": [
        {
            "value": "--grammar-file cline.gbnf",
            "enabled": false
        }
    ],
    "reasoning_format": "",
    "ubatch_size": "",
    "n_predict": "",
    "ignore_eos": false,
    "temp": "",
    "top_k": "",
    "top_p": "",
    "repeat_penalty": ""
}